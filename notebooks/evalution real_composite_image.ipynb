{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7638775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sunjinsheng/codebase/harmer_hdnet\n"
     ]
    }
   ],
   "source": [
    "%cd /sun/codebase/harmer_hdnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a3e96d-4e98-489d-ab5e-e090c0860cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage import data, io\n",
    "\n",
    "# from options.train_options import TrainOptions\n",
    "# from data import CustomDataset\n",
    "# from models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca1de45-0bab-40a9-badc-a016a12f1f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensor2im(input_image, imtype=np.uint8):\n",
    "    \"\"\"\"Converts a Tensor array into a numpy image array.\n",
    "\n",
    "    Parameters:\n",
    "        input_image (tensor) --  the input image tensor array\n",
    "        imtype (type)        --  the desired type of the converted numpy array\n",
    "    \"\"\"\n",
    "    if not isinstance(input_image, np.ndarray):\n",
    "        if isinstance(input_image, torch.Tensor):  # get the data from a variable\n",
    "            image_tensor = input_image.data\n",
    "        else:\n",
    "            return input_image\n",
    "        image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array\n",
    "        if image_numpy.shape[0] == 1:  # grayscale to RGB\n",
    "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  # post-processing: tranpose and scaling\n",
    "    else:  # if it is a numpy array, do nothing\n",
    "        image_numpy = input_image\n",
    "    return image_numpy.astype(imtype)\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def calculateMean(vars):\n",
    "    return sum(vars) / len(vars)\n",
    "\n",
    "def save_img(path, img):\n",
    "    fold, name = os.path.split(path)\n",
    "    os.makedirs(fold, exist_ok=True)\n",
    "    io.imsave(path, img)\n",
    "\n",
    "def resolveResults(results):\n",
    "    interval_metrics = {}\n",
    "    mask, mse, psnr, fmse, ssim = np.array(results['mask']), np.array(results['mse']), np.array(results['psnr']), np.array(results['fmse']), np.array(results['ssim'])\n",
    "    interval_metrics['0.00-0.05'] = [np.mean(mse[np.logical_and(mask <= 0.05, mask > 0.0)]),\n",
    "                                    np.mean(psnr[np.logical_and(mask <= 0.05, mask > 0.0)]),\n",
    "                                    np.mean(fmse[np.logical_and(mask <= 0.05, mask > 0.0)]),\n",
    "                                    np.mean(ssim[np.logical_and(mask <= 0.05, mask > 0.0)])]\n",
    "\n",
    "    interval_metrics['0.05-0.15'] = [np.mean(mse[np.logical_and(mask <= 0.15, mask > 0.05)]),\n",
    "                                    np.mean(psnr[np.logical_and(mask <= 0.15, mask > 0.05)]),\n",
    "                                    np.mean(fmse[np.logical_and(mask <= 0.15, mask > 0.05)]),\n",
    "                                    np.mean(ssim[np.logical_and(mask <= 0.15, mask > 0.05)])]\n",
    "\n",
    "    interval_metrics['0.15-1.00'] = [np.mean(mse[mask > 0.15]),\n",
    "                                    np.mean(psnr[mask > 0.15]),\n",
    "                                    np.mean(fmse[mask > 0.15]),\n",
    "                                    np.mean(ssim[mask > 0.15])]\n",
    "\n",
    "    print(interval_metrics)\n",
    "    return interval_metrics\n",
    "\n",
    "def updateWriterInterval(writer, metrics, epoch):\n",
    "    for k, v in metrics.items():\n",
    "        writer.add_scalar('interval/{}-MSE'.format(k), v[0], epoch)\n",
    "        writer.add_scalar('interval/{}-PSNR'.format(k), v[1], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e9ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "opt = Namespace(dataset_root='datasets/HAdobe5k', name='', gpu_ids=[0], checkpoints_dir='/sun/home_logs/instance_harmer/results0320', is_train=False, model='hdnet', input_nc=3, output_nc=3, ngf=32, ndf=64, netD='basic', netG='hdnet', n_layers_D=3, normD='instance', normG='RAIN', init_type='normal', init_gain=0.02, no_dropout=False, dataset_mode='iharmony4', serial_batches=False, num_threads=32, batch_size=12, load_size=256, crop_size=256, max_dataset_size=np.inf, preprocess='none', display_winsize=256, epoch='latest', load_iter=0, verbose=False, suffix='', display_freq=500, display_id=1, display_server='http://localhost', display_env='main', display_port=8097, update_html_freq=500, print_freq=300, no_html=False, save_latest_freq=5000, save_epoch_freq=1, save_by_iter=False, continue_train=False, epoch_count=1, phase='train', niter=120, niter_decay=0, beta1=0.9, lr=0.001, g_lr_ratio=1.0, d_lr_ratio=1.0, gan_mode='vanilla', pool_size=0, lr_policy='target_decay', lr_decay_iters=100, lambda_L1=1.0, lambda_Fft=0.0, gp_ratio=1.0, lambda_a=1.0, lambda_v=1.0, isTrain=True)\n",
    "# setup_seed(6)\n",
    "# list_args = [\"--dataset_root\", \"datasets/Hday2night\", \"--checkpoints_dir\", \"/sun/home_logs/hdnet/evaluate/results0721\",\n",
    "#              \"--name\", \"\", \"--batch_size\", \"12\", \"--is_train\", 0]\n",
    "# opt = TrainOptions().parse(args=list_args)   # get training \n",
    "# test_dataset = CustomDataset(opt, is_for_train=False)\n",
    "# test_dataset_size = len(test_dataset)\n",
    "# print('The number of testing images = %d' % test_dataset_size)\n",
    "\n",
    "# test_dataloader = test_dataset.load_data()\n",
    "# print('The total batches of training images = %d' % len(test_dataset.dataloader))\n",
    "opt_2 = Namespace()\n",
    "opt_2.dataset_root = '/sun/home_datasets/iharmony4/HAdobe5k'\n",
    "opt_2.preprocess = 'resize'\n",
    "opt_2.load_size = 256\n",
    "opt_2.batch_size = 16\n",
    "opt_2.num_threads = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6e1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training file...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from data.real_dataset import RealDataset\n",
    "is_for_train = False\n",
    "dataset = RealDataset(opt_2)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=is_for_train,\n",
    "            num_workers=int(opt_2.num_threads),\n",
    "            drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc45147-19b7-47c1-9326-8abd1e56508d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = create_model(opt)      # create a model given opt.model and other options\n",
    "# model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "# model.netG.eval()\n",
    "from models.networks import HDNet\n",
    "from models.normalize import RAIN\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "ngf = 32\n",
    "norm_layer = RAIN\n",
    "use_dropout = False\n",
    "use_attention = True\n",
    "model = HDNet(input_nc, output_nc, ngf, norm_layer=norm_layer, use_dropout=use_dropout, use_attention=True)\n",
    "model.load_state_dict(torch.load('/sun/codebase/harmer_hdnet/home_logs/old_version/results_0701/latest_net_G.pth', map_location='cpu'))\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "# total_iters = 0                # the total number of training iterations\n",
    "# writer = SummaryWriter(os.path.join(opt.checkpoints_dir, opt.name))\n",
    "\n",
    "# evaluate for every epoch\n",
    "epoch = 0\n",
    "max_psnr=0\n",
    "# epoch_mse, epoch_psnr, epoch_interval_metrics = evaluateModel(epoch, model, opt, test_dataloader, 'eval', max_psnr)\n",
    "# def evaluateModel(epoch_number, model, opt, test_dataset, epoch, max_psnr, iters=None):\n",
    "epoch_number = epoch\n",
    "iters = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8afa883d-2603-45d6-ba7a-2c668a17d745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag_save_img = True\n",
    "eval_results_path = os.path.join('/sun/home_logs/instance_harmer/','results0320')\n",
    "csv_eval = os.path.join(eval_results_path, 'eval.csv')\n",
    "\n",
    "total_eval_results = {'mask': [], 'mse': [], 'psnr': [], 'fmse':[], 'ssim':[]}\n",
    "# if iters is not None:\n",
    "#     eval_path = os.path.join(opt.checkpoints_dir, opt.name, 'Eval_%s_iter%d.csv' % (epoch, iters))  # define the website directory\n",
    "# else:\n",
    "#     eval_path = os.path.join(opt.checkpoints_dir, opt.name, 'Eval_%s.csv' % (epoch))  # define the website directory\n",
    "# util.mkdir(eval_results_path)\n",
    "flag_exists = os.path.exists(csv_eval)\n",
    "# eval_results_fstr = open(csv_eval, 'a')\n",
    "# if not flag_exists:\n",
    "#     eval_results_fstr.writelines('img_path,mask_ratio,mse,psnr,fmse,ssim\\n') \n",
    "\n",
    "# eval_results = {'mask': [], 'mse': [], 'psnr': [], 'fmse':[], 'ssim':[]}\n",
    "\n",
    "root = Path('/sun/home_logs/instance_harmer/real_image_results/instance2')\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "it = len(dataloader)\n",
    "times = torch.zeros(it)     # 存储每轮iteration的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc35c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bda16bfe7424dd5a1f3afb896a6d4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 525 ms, total: 1min 14s\n",
      "Wall time: 7.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, data in tqdm(enumerate(dataloader), total = len(dataloader)):\n",
    "    # model.set_input(data)  # unpack data from data loader\n",
    "    model.comp = data['comp'].cuda()\n",
    "    model.mask = data['mask'].cuda()\n",
    "    paths = data['img_path']\n",
    "    model.inputs = model.comp\n",
    "    # comp = model.comp\n",
    "    # torch.save(comp, \"comp_2.pt\")\n",
    "\n",
    "    # model.test()  # inference\n",
    "    with torch.no_grad():\n",
    "        # model.forward()\n",
    "        starter.record()\n",
    "        model.output = model(model.comp, model.mask)\n",
    "        ender.record()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        curr_time = starter.elapsed_time(ender) # 计算时间\n",
    "        times[i] = curr_time\n",
    "\n",
    "        model.attentioned = model.output * model.mask + model.inputs[:,:3,:,:] * (1 - model.mask)\n",
    "        model.fake_f = model.output * model.mask\n",
    "        model.harmonized = model.attentioned\n",
    "        output = model.attentioned\n",
    "\n",
    "        for i_img in range(output.size(0)):\n",
    "            img_path = paths[i_img]\n",
    "            img_name = img_path.split('/')[-1]\n",
    "            save_path = root/img_name\n",
    "            pred = output[i_img:i_img+1]\n",
    "            img_pred = tensor2im(pred)\n",
    "            img = Image.fromarray(img_pred)\n",
    "            img.save(str(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d76ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad2851b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.instancenorm.InstanceNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_softmax() for <class 'torch.nn.modules.activation.Softmax'>.\n",
      "48041641920.0 10408495.0\n"
     ]
    }
   ],
   "source": [
    "flops, params = profile(model, inputs=(model.comp, model.mask))\n",
    "print(flops, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70df3046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flops:  48041641920.0 params:  10408495.0\n",
      "flops: 48041.64 M, params: 10.41 M\n"
     ]
    }
   ],
   "source": [
    "print('flops: ', flops, 'params: ', params)\n",
    "print('flops: %.2f M, params: %.2f M' % (flops / 1000000.0, params / 1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "748b66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 19.308174, FPS: 51.79153622171355 \n"
     ]
    }
   ],
   "source": [
    "mean_time = times.mean().item()\n",
    "print(\"Inference time: {:.6f}, FPS: {} \".format(mean_time, 1000/mean_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
